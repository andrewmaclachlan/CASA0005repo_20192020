@article{Arribas-Bel2019,
author = {Arribas-Bel, Dani},
doi = {10.21105/jose.00042},
file = {:C$\backslash$:/Users/Andy/Downloads/10.21105.jose.00042.pdf:pdf},
journal = {Journal of Open Source Education},
number = {14},
pages = {42},
title = {{A course on Geographic Data Science}},
volume = {2},
year = {2019}
}
@article{Brunsdon1996,
abstract = {Geographically weighted regression (GWR) is a local form of spatial analysis introduced in 1996 in the geographical literature drawing from statistical approaches for curve-fitting and smoothing applications. The method works based on the simple yet powerful idea of estimating local models using subsets of observations centered on a focal point. Since its introduction, GWR rapidly captured the attention of many in geography and other fields for its potential to investigate nonstationary relations in regression analysis. The basic concepts have also been used to obtain local descriptive statistics and other models such as Poisson regression and probit. The method has been instrumental in highlighting the existence of potentially complex spatial relationships. At the same time, there have been a number of debates concerning the nature and range of applications of the method, including its use for inferential analysis or interpolation. The evidence available suggests that GWR is a useful, if imperfect, tool for inferring spatial processes, and a relatively simple and effective tool for spatial interpolation. Related technical developments enhance GWR (e.g., autocorrelation tests and multiple comparison adjustments) and/or complement it (e.g., the expansion method). Other approaches provide alternatives to the use of GWR (e.g., kriging and Bayesian models).},
author = {Brunsdon, Chris and Fotheringham, A. Stewart and Charlton, Martin E.},
doi = {10.1016/B978-008044910-4.00447-8},
file = {:C$\backslash$:/Users/Andy/Downloads/j.1538-4632.1996.tb00936.x.pdf:pdf},
isbn = {9780080449104},
journal = {Geographical analysis},
keywords = {Bandwidth,Cross-validation,Distance decay,Geographically weighted regression,Kernel function,Local forms of spatial analysis,Moving window,Multicollinearity,Nearest neighbors,Nonstationarity,Quantitative geography,Regression analysis,Regression diagnostics,Spatial statistics},
number = {4},
pages = {281--298},
title = {{Geographically weighted regression: a method for exploring spatial nonstationarity}},
volume = {28},
year = {1996}
}
@techreport{Cosh2020,
author = {Cosh, Georgie},
booktitle = {GLA Housing and Land},
file = {:C$\backslash$:/Users/Andy/Downloads/housing{\_}research{\_}note{\_}4-{\_}short-term{\_}and{\_}holiday{\_}letting{\_}in{\_}london.pdf:pdf},
title = {{GLA Housing and Land Short-term and holiday letting in London}},
year = {2020}
}
@article{Donoho2017,
abstract = {More than 50 years ago, John Tukey called for a reformation of academic statistics. In “The Future of Data Analysis,” he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or “data analysis.” Ten to 20 years ago, John Chambers, Jeff Wu, Bill Cleveland, and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland and Wu even suggested the catchy name “data science” for this envisioned field. A recent and growing phenomenon has been the emergence of “data science” programs at major universities, including UC Berkeley, NYU, MIT, and most prominently, the University of Michigan, which in September 2015 announced a {\$}100M “Data Science Initiative” that aims to hire 35 new faculty. Teaching in these new programs has significant overlap in curricular subject matter with traditional statistics courses; yet many academic statisticians perceive the new programs as “cultural appropriation.” This article reviews some ingredients of the current “data science moment,” including recent commentary about data science in the popular media, and about how/whether data science is really different from statistics. The now-contemplated field of data science amounts to a superset of the fields of statistics and machine learning, which adds some technology for “scaling up” to “big data.” This chosen superset is motivated by commercial rather than intellectual developments. Choosing in this way is likely to miss out on the really important intellectual event of the next 50 years. Because all of science itself will soon become data that can be mined, the imminent revolution in data science is not about mere “scaling up,” but instead the emergence of scientific studies of data analysis science-wide. In the future, we will be able to predict how a proposal to change data analysis workflows would impact the validity of data analysis across all of science, even predicting the impacts field-by-field. Drawing on work by Tukey, Cleveland, Chambers, and Breiman, I present a vision of data science based on the activities of people who are “learning from data,” and I describe an academic field dedicated to improving that activity in an evidence-based manner. This new field is a better academic enlargement of statistics and machine learning than today's data science initiatives, while being able to accommodate the same short-term goals. Based on a presentation at the Tukey Centennial Workshop, Princeton, NJ, September 18, 2015.},
author = {Donoho, David},
doi = {10.1080/10618600.2017.1384734},
file = {:C$\backslash$:/Users/Andy/Downloads/50 Years of Data Science.pdf:pdf},
issn = {15372715},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Cross-study analysis,Data analysis,Data science,Meta analysis,Predictive modeling,Quantitative programming environments,Statistics},
number = {4},
pages = {745--766},
publisher = {Taylor {\&} Francis},
title = {{50 Years of Data Science}},
url = {https://doi.org/10.1080/10618600.2017.1384734},
volume = {26},
year = {2017}
}
@incollection{Efron1988,
abstract = {The asymptotic behaviour of the residual life time at time t is investigated (for t rightarrow infty). We derive weak limit laws and their domains of attraction and treat rates of convergence and moment convergence. The presentation exploits the close similarity with extreme value theory.},
address = {New York, NY},
author = {Efron, B},
booktitle = {Breakthroughs in statistics},
file = {:C$\backslash$:/Users/Andy/Downloads/euclid.aos.1176344552.pdf:pdf},
issn = {0091-1798},
number = {5},
pages = {569--593},
publisher = {Springer},
title = {{Bootstrap methods: another look at the jackknife}},
url = {http://projecteuclid.org/euclid.aop/1176996548},
volume = {2},
year = {1988}
}
@inproceedings{Ester1996,
abstract = {Clustering techniques are often used for data exploration. In the literature, there are many examples of applications of different clustering methods. The density-based approaches form a separate group within the clustering techniques since they take into account the density of the data. Using the density of data as a similarity measure is practical in many real situations, because clusters of arbitrary shapes can be handled, what is not possible with convectional clustering methods.{\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"{o}}rg and Xiaowe, Xu},
booktitle = {Kdd},
doi = {10.1016/B978-044452701-1.00067-3},
file = {:C$\backslash$:/Users/Andy/Downloads/KDD96-037.pdf:pdf},
isbn = {9780444527011},
keywords = {Color maps,Core plot,Density-based techniques,Inliers,Natural clusters,Outliers,Reachability plot},
pages = {226--231},
title = {{A density-based algorithm for discovering clusters in large spatial databases with noise}},
volume = {96},
year = {1996}
}
@book{Fung,
address = {London},
author = {Fung, Dilly},
edition = {2nd},
file = {:C$\backslash$:/Users/Andy/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fung - 2017 - UCL Connected Curriculum.pdf:pdf},
publisher = {UCL Press},
title = {{UCL Connected Curriculum}},
year = {2017}
}
@misc{Glassdoor2020,
author = {Glassdoor},
booktitle = {Glassdoor},
title = {{50 Best Jobs in America for 2019}},
url = {https://www.glassdoor.com/List/Best-Jobs-in-America-2019-LST{\_}KQ0,25.htm},
urldate = {2020-04-07},
year = {2020}
}
@book{Grolemund2017,
author = {Grolemund, Garrett. and Wickham, Hadley.},
publisher = {O'Reilly},
title = {{R for Data Science}},
year = {2017}
}
@article{Guha2018,
abstract = {The present study focuses on determining the relationship of estimated land surface temperature (LST) with normalized difference vegetation index (NDVI) and normalized difference built-up index (NDBI) for Florence and Naples cities in Italy using Landsat 8 data. The study also classifies different land use/land cover LU–LC) types using NDVI and NDBI threshold values, iterative self-organizing data analysis technique and maximum likelihood classifier, and analyses the relationship built by LST with the built-up area and bare land. Urban thermal field variance index was applied to determine the thermal and ecological comfort level of the city. Several urban heat islands (UHIs) were extracted as the most heated zones within the city boundaries due to increasing anthropogenic activities. The difference between the mean LST of UHI and non-UHI is 3.15°C and 3.31°C, respectively, for Florence and Naples. LST build a strong correlation with NDVI (negative) and NDBI (positive) for both the cities as a whole, especially for the non-UHIs. But, the strength of correlation becomes much weaker within the UHIs. Moreover, most of the UHIs (85.21{\%} in Naples and 76.62{\%} in Florence) are developed within the built-up area or bare land and are demarcated as an ecologically stressed zone.},
author = {Guha, Subhanil and Govil, Himanshu and Dey, Anindita and Gill, Neetu},
doi = {10.1080/22797254.2018.1474494},
file = {:C$\backslash$:/Users/Andy/Downloads/Analytical study of land surface temperature with NDVI and NDBI using Landsat 8 OLI and TIRS data in Florence and Naples city Italy.pdf:pdf},
issn = {22797254},
journal = {European Journal of Remote Sensing},
keywords = {Land surface temperature (LST),land use/land cover (LU–LC),normalized difference built-up index (NDBI),normalized difference vegetation index (NDVI),urban heat island (UHI),urban thermal field variance index (UTFVI)},
number = {1},
pages = {667--678},
publisher = {Taylor {\&} Francis},
title = {{Analytical study of land surface temperature with NDVI and NDBI using Landsat 8 OLI and TIRS data in Florence and Naples city, Italy}},
url = {https://doi.org/10.1080/22797254.2018.1474494},
volume = {51},
year = {2018}
}
@article{Hahmann2013,
abstract = {The aim of this article is to provide a basis in evidence for (or against) the much-quoted assertion that 80{\%} of all information is geospatially referenced. For this purpose, two approaches are presented that are intended to capture the portion of geospatially referenced information in user-generated content: a network approach and a cognitive approach. In the network approach, the German Wikipedia is used as a research corpus. It is considered a network with the articles being nodes and the links being edges. The Network Degree of Geospatial Reference (NDGR) is introduced as an indicator to measure the network approach. We define NDGR as the shortest path between any Wikipedia article and the closest article within the network that is labeled with coordinates in its headline. An analysis of the German Wikipedia employing this approach shows that 78{\%} of all articles have a coordinate themselves or are directly linked to at least one article that has geospatial coordinates. The cognitive approach is manifested by the categories of geospatial reference (CGR): direct, indirect, and non-geospatial reference. These are categories that may be distinguished and applied by humans. An empirical study including 380 participants was conducted. The results of both approaches are synthesized with the aim to (1) examine correlations between NDGR and the human conceptualization of geospatial reference and (2) to separate geospatial from non-geospatial information. From the results of this synthesis, it can be concluded that 56-59{\%} of the articles within Wikipedia can be considered to be directly or indirectly geospatially referenced. The article thus describes a method to check the validity of the '80{\%}-assertion' for information corpora that can be modeled using graphs (e.g., the World Wide Web, the Semantic Web, and Wikipedia). For the corpus investigated here (Wikipedia), the '80{\%}-assertion' cannot be confirmed, but would need to be reformulated as a '60{\%}-assertion'. {\textcopyright} 2013 Copyright Taylor and Francis Group, LLC.},
author = {Hahmann, Stefan and Burghardt, Dirk},
doi = {10.1080/13658816.2012.743664},
file = {:C$\backslash$:/Users/Andy/Downloads/How much information is geospatially referenced Networks and cognition.pdf:pdf},
issn = {13658816},
journal = {International Journal of Geographical Information Science},
keywords = {Wikipedia,cognition of geographic information,geographic information retrieval,geospatial reference,scale-free networks},
number = {6},
pages = {1171--1189},
title = {{How much information is geospatially referenced? Networks and cognition}},
volume = {27},
year = {2013}
}
@article{Kahn2005,
abstract = {This chapter discusses Guattari's ecosophy, placing his work within the extant literature on environmental education and science and technology studies; defining key terms and examining ecosophy as a philosophy radical and encompassing enough to make intelligible the dynamic connections between various fields of existence. It then offers a 'reading' of two different pedagogical strategies that have achieved a wide following in the last few decades: direct instruction, and critical pedagogy. Reading these pedagogies through ecosophy allows us to name more fully the troubling assumptions and lacunae of these pedagogical strategies. The chapter also explores connections between individuals, communities, practices, and the nonhuman (material) world. Finally, the chapter argues not only that education is a matter of connection to people and communities, but also that education involves an exploration and reimagining of our connections to things, processes, and living systems.},
author = {Kahn, Peter and O'Rourke, Karen},
doi = {10.1002/9781118944707.ch10},
file = {:C$\backslash$:/Users/Andy/Downloads/10.1.1.461.5829.pdf:pdf},
isbn = {9781118944707},
journal = {Handbook of Enquiry {\&} Problem Based Learning},
keywords = {Critical pedagogy,Direct instruction,Environmental education,Guattari's ecosophy,Pedagogical strategies},
pages = {1--12},
title = {{Understanding enquiry-based learning}},
year = {2005}
}
@incollection{Kwan2009,
address = {New York},
author = {Kwan, Anna},
booktitle = {The Routledge International Handbook of Higher Education},
editor = {Tight, Malcolm and Mok, Ka Ho and Huisman, Jeroen and Morphew, Christopher},
publisher = {Taylor {\&} Francis},
title = {{Problem-based Learning}},
year = {2009}
}
@article{Lage2000,
author = {Lage, Maureen J. and Platt, Glenn J. and Treglia, Michael},
doi = {10.1080/00220480009596759},
file = {:C$\backslash$:/Users/Andy/Downloads/1183338.pdf:pdf},
issn = {21524068},
journal = {Journal of Economic Education},
number = {1},
pages = {30--43},
title = {{Inverting the classroom: A gateway to creating an inclusive learning environment}},
volume = {31},
year = {2000}
}
@article{Li2016,
abstract = {Big data has now become a strong focus of global interest that is increasingly attracting the attention of academia, industry, government and other organizations. Big data can be situated in the disciplinary area of traditional geospatial data handling theory and methods. The increasing volume and varying format of collected geospatial big data presents challenges in storing, managing, processing, analyzing, visualizing and verifying the quality of data. This has implications for the quality of decisions made with big data. Consequently, this position paper of the International Society for Photogrammetry and Remote Sensing (ISPRS) Technical Commission II (TC II) revisits the existing geospatial data handling methods and theories to determine if they are still capable of handling emerging geospatial big data. Further, the paper synthesises problems, major issues and challenges with current developments as well as recommending what needs to be developed further in the near future.},
author = {Li, Songnian and Dragicevic, Suzana and Castro, Francesc Ant{\'{o}}n and Sester, Monika and Winter, Stephan and Coltekin, Arzu and Pettit, Christopher and Jiang, Bin and Haworth, James and Stein, Alfred and Cheng, Tao},
doi = {10.1016/j.isprsjprs.2015.10.012},
file = {:C$\backslash$:/Users/Andy/Downloads/1-s2.0-S0924271615002439-main.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Analytics,Big data,Data handling,Geospatial,Review,Spatial modeling},
pages = {119--133},
publisher = {International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)},
title = {{Geospatial big data handling theory and methods: A review and research challenges}},
url = {http://dx.doi.org/10.1016/j.isprsjprs.2015.10.012},
volume = {115},
year = {2016}
}
@book{Lovelace2019,
abstract = {Book on geographic data with R.},
author = {Lovelace, Robin. and Nowosad, Jakub. and Muenchow, Jannes.},
doi = {10.1201/9780203730058},
isbn = {1-138-30451-4},
publisher = {CRC Press},
title = {{Geocomputation with R}},
year = {2019}
}
@misc{Pattabiraman2019,
author = {Pattabiraman, Kumaresh},
booktitle = {LinkedIn official blog},
title = {{LinkedIn's Most Promising Jobs of 2019}},
url = {https://blog.linkedin.com/2019/january/10/linkedins-most-promising-jobs-of-2019},
urldate = {2020-04-07},
year = {2019}
}
@article{Support2014,
author = {Support, Programme Management},
file = {:C$\backslash$:/Users/Andy/Downloads/603320.pdf:pdf},
number = {June},
pages = {1--2},
title = {{Job Description Job Description}},
year = {2014}
}
@misc{TheUniversitiesandCollegesAdmissionsService2020,
author = {{The Universities and Colleges Admissions Service}},
title = {{UCAS Postgraduate courses}},
url = {https://digital.ucas.com/coursedisplay/results/providers?studyYear=2019{\&}destination=Postgraduate{\&}postcodeDistanceSystem=imperial{\&}pageNumber=1{\&}sort=MostRelevant{\&}searchTerm=data science},
urldate = {2020-04-07},
year = {2020}
}
@article{Tucker2012,
abstract = {Four years ago, in the shadow of Colorado's Pike's Peak, veteran Woodland Park High School chemistry teachers Jonathan Bergmann and Aaron Sams stumbled onto an idea. Struggling to find the time to reteach lessons for absent students, they plunked down {\$}50, bought software that allowed them to record and annotate lessons, and posted them online. Absent students appreciated the opportunity to see what they missed. But, surprisingly, so did students who hadn't missed class. They, too, used the online material, mostly to review and reinforce classroom lessons. And, soon, Bergmann and Sams realized they had the opportunity to radically rethink how they used class time. It's called “the flipped classroom.” While there is no one model, the core idea is to flip the common instructional approach: With teacher-created videos and interactive lessons, instruction that used to occur in class is now accessed at home, in advance of class. Class becomes the place to work through problems, advance concepts, and engage in collaborative learning. Most importantly, all aspects of instruction can be rethought to best maximize the scarcest learning resource—time. Flipped classroom teachers almost universally agree that it's not the instructional videos on their own, but how they are integrated into an overall approach, that makes the difference. In his classes, Bergmann says, students can't just “watch the video and be done with it.” He checks their notes and requires each student to come to class with a question. And, while he says it takes a little while for students to get used to the system, as the year progresses he sees them asking better questions and thinking more deeply about the content. After flipping his classroom, Bergmann says he can more easily query individual students, probe for misconceptions around scientific concepts, and clear up incorrect notions.},
author = {Tucker, Bill},
file = {:C$\backslash$:/Users/Andy/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tucker - 2012 - The flipped classroom Online instruction at home frees class time for learning.pdf:pdf},
isbn = {15399664},
issn = {15399664},
journal = {Education Next},
pages = {p. 82--83},
pmid = {1237826701},
title = {{The flipped classroom: Online instruction at home frees class time for learning}},
volume = {12},
year = {2012}
}
@book{Xie2016,
author = {Xie, Yihui},
publisher = {CRC Press},
title = {{Bookdown: Authoring books and technical documents with R markdown}},
year = {2016}
}
